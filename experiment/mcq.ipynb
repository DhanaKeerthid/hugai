{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import traceback   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (3.10.8)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (0.2.41)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (0.1.129)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (0.2.17)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (3.10.8)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.16 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (0.2.16)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.39 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (0.2.41)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (0.1.129)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.13.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.39->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.39->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.39->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (4.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.39->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (4.45.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (3.10.8)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (0.2.41)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (0.1.129)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain huggingface_hub transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFaceHub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HuggingFaceHub_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HuggingFaceHub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use a model that supports text-generation, such as a GPT-based model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceHub\u001b[49m(\n\u001b[0;32m      3\u001b[0m     huggingfacehub_api_token\u001b[38;5;241m=\u001b[39mHuggingFaceHub_api_token,  \u001b[38;5;66;03m# API token\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m,                                     \u001b[38;5;66;03m# Use a GPT-2 model for text generation\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m'\u001b[39m                              \u001b[38;5;66;03m# Define the task as 'text-generation'\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Use the model to generate a response for the multiple-choice question\u001b[39;00m\n\u001b[0;32m      9\u001b[0m response \u001b[38;5;241m=\u001b[39m llm(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is the capital of France? Choices: London, Paris, Berlin, Rome\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'HuggingFaceHub' is not defined"
     ]
    }
   ],
   "source": [
    "# Use a model that supports text-generation, such as a GPT-based model\n",
    "llm = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=HuggingFaceHub_api_token,  # API token\n",
    "    repo_id='gpt2',                                     # Use a GPT-2 model for text generation\n",
    "    task='text-generation'                              # Define the task as 'text-generation'\n",
    ")\n",
    "\n",
    "# Use the model to generate a response for the multiple-choice question\n",
    "response = llm(\"What is the capital of France? Choices: London, Paris, Berlin, Rome\")\n",
    "print(response) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_huggingface in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (0.0.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_huggingface) (0.25.1)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_huggingface) (0.2.41)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_huggingface) (3.1.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_huggingface) (0.20.0)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain_huggingface) (4.45.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.1.129)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (8.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.10.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (1.24.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.8.30)\n",
      "Requirement already satisfied: sympy in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain_huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface) (4.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_huggingface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\" \n",
    "HuggingFaceHub_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France? Choices: London, Paris, Berlin, Rome. Answer: What is the capital of France? Choices: London, Paris, Berlin, Rome.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "import os\n",
    "\n",
    "# Ensure your Hugging Face API token is set correctly\n",
    "HuggingFaceHub_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "# Create an instance of HuggingFaceHub using a GPT-based model\n",
    "llm = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=HuggingFaceHub_api_token,  # API token\n",
    "    repo_id='gpt2',                                     # Use a GPT-2 model for text generation\n",
    "    task='text-generation'                              # Define the task as 'text-generation'\n",
    ")\n",
    "\n",
    "# Define the questions to ask\n",
    "questions = [\n",
    "    \"What is the capital of France? Choices: London, Paris, Berlin, Rome.\",\n",
    "    \"What is the capital of Germany? Choices: London, Paris, Berlin, Rome.\",\n",
    "    \"What is the capital of Italy? Choices: London, Paris, Berlin, Rome.\"\n",
    "]\n",
    "\n",
    "# Loop through each question and generate a response\n",
    "for question in questions:\n",
    "    response = llm(question)\n",
    "    print(f\"{question} Answer: {response}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France? Choices: London, Paris, Berlin, Rome. Answer: Please answer the following question with only one correct option: What is the capital of France? Choices: London, Paris, Berlin, Rome.\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is London.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is London.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is London.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is London.\n",
      "\n",
      "The capital of France is Rome.\n",
      "\n",
      "The capital of France is London.\n",
      "What is the capital of Germany? Choices: London, Paris, Berlin, Rome. Answer: Please answer the following question with only one correct option: What is the capital of Germany? Choices: London, Paris, Berlin, Rome.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "The capital of Germany is Rome.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "\n",
      "The capital of Germany is Berlin.\n",
      "What is the capital of Italy? Choices: London, Paris, Berlin, Rome. Answer: Please answer the following question with only one correct option: What is the capital of Italy? Choices: London, Paris, Berlin, Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "The capital of Italy is Rome.\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "import os\n",
    "\n",
    "# Ensure your Hugging Face API token is set correctly\n",
    "HuggingFaceHub_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n",
    "\n",
    "# Create an instance of HuggingFaceHub using a GPT-based model\n",
    "llm = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=HuggingFaceHub_api_token,  # API token\n",
    "    repo_id='gpt2',                                     # Use a GPT-2 model for text generation\n",
    "    task='text-generation'                              # Define the task as 'text-generation'\n",
    ")\n",
    "\n",
    "# Define the questions to ask\n",
    "questions = [\n",
    "    \"What is the capital of France? Choices: London, Paris, Berlin, Rome.\",\n",
    "    \"What is the capital of Germany? Choices: London, Paris, Berlin, Rome.\",\n",
    "    \"What is the capital of Italy? Choices: London, Paris, Berlin, Rome.\"\n",
    "]\n",
    "\n",
    "# Loop through each question and generate a response\n",
    "for question in questions:\n",
    "    # Generate a concise response\n",
    "    prompt = f\"Please answer the following question with only one correct option: {question}\"\n",
    "    response = llm(prompt)\n",
    "    print(f\"{question} Answer: {response.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=HuggingFaceHub_api_token,\n",
    "    repo_id='google/flan-t5-large',  # Using DistilGPT-2 for potentially faster response\n",
    "    task='text-generation'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceHub(client=<InferenceClient(model='google/flan-t5-large', timeout=None)>, repo_id='google/flan-t5-large', task='text-generation', huggingfacehub_api_token='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')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France? Choices: London, Paris, Berlin, Rome. Answer: Paris\n",
      "What is the capital of Germany? Choices: London, Paris, Berlin, Rome. Answer: Berlin\n",
      "What is the capital of Italy? Choices: London, Paris, Berlin, Rome. Answer: Rome\n"
     ]
    }
   ],
   "source": [
    "# Define the questions to ask\n",
    "questions = [\n",
    "    \"What is the capital of France? Choices: London, Paris, Berlin, Rome.\",\n",
    "    \"What is the capital of Germany? Choices: London, Paris, Berlin, Rome.\",\n",
    "    \"What is the capital of Italy? Choices: London, Paris, Berlin, Rome.\"\n",
    "]\n",
    "\n",
    "# Loop through each question and generate a response\n",
    "for question in questions:\n",
    "    # Generate a concise response\n",
    "    prompt = f\"Please answer the following question with only one correct option: {question}\"\n",
    "    response = llm(prompt)\n",
    "    print(f\"{question} Answer: {response.strip()}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=HuggingFaceHub_api_token,\n",
    "    repo_id='google/flan-t5-large',  # Using DistilGPT-2 for potentially faster response\n",
    "    task='text-generation',\n",
    "    model_kwargs={\"temperature\": 0.4 } \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceHub(client=<InferenceClient(model='google/flan-t5-large', timeout=None)>, repo_id='google/flan-t5-large', task='text-generation', model_kwargs={'temperature': 0.4}, huggingfacehub_api_token='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')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\dhana\\hugai\\env\\lib\\site-packages (from PyPDF2) (4.12.2)\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \n",
    "create a quiz of {number} multiple choice questions for machine learning students in a {tone} tone. \n",
    "Make sure the questions are not repeated and ensure all the questions conform to the text. \n",
    "Format your response using the RESPONSE_JSON format below as a guide. \n",
    "Ensure to create {number} MCQs.\n",
    "\n",
    "### RESPONSE_JSON\n",
    "{response_json} \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import HuggingFaceHub\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\" \n",
    "HuggingFaceHub_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    huggingfacehub_api_token=HuggingFaceHub_api_token,\n",
    "    repo_id='google/flan-t5-large',  # Using DistilGPT-2 for potentially faster response\n",
    "    task='text-generation'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz} \n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"], template=TEMPLATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r\"C:\\Users\\dhana\\hugai\\data.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    TEXT = file.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions.[1] Quick progress in the field of deep learning, beginning in 2010s, allowed neural networks to surpass many previous approaches in performance\n"
     ]
    }
   ],
   "source": [
    "print(TEXT) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the Python dictionary into a JSON-formatted string\n",
    "json.dumps(RESPONSE_JSON)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5 \n",
    "SUBJECT=\"Machine learning\" \n",
    "TONE=\"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\" \n",
    "HuggingFaceHub_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN']=\"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\" \n",
    "HuggingFaceHub_api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\\n\\nBiologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\\n\\nLife on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment. \\n',\n",
       " 'number': 5,\n",
       " 'subject': 'biology',\n",
       " 'tone': 'simple',\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '\\nText: Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\\n\\nBiologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\\n\\nLife on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment. \\n\\nYou are an expert MCQ maker. Based on the subject biology, please create a quiz of 5 multiple choice questions in simple tone. \\nMake sure to format your response like the RESPONSE_JSON structure provided below:\\n### RESPONSE_JSON\\n{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\\nThe answer is a simple question, and it is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple',\n",
       " 'review': '\\nYou are an expert English grammarian and writer. Given a Multiple Choice Quiz for biology students.\\nYou need to evaluate the complexity of the questions and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \\nIf the quiz is not up to the cognitive and analytical abilities of the students, update the quiz questions that need to be changed and adjust the tone to fit the student abilities.\\nQuiz_MCQs:\\n\\nText: Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\\n\\nBiologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\\n\\nLife on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment. \\n\\nYou are an expert MCQ maker. Based on the subject biology, please create a quiz of 5 multiple choice questions in simple tone. \\nMake sure to format your response like the RESPONSE_JSON structure provided below:\\n### RESPONSE_JSON\\n{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\\nThe answer is a simple question, and it is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple question.\\nThe answer is a simple\\n\\nCheck from an expert English Writer of the above quiz:\\nYou are an expert English grammarian and writer. Given a Multiple Choice Quiz for biology students.\\nYou need to evaluate the complexity of the questions and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. Only use at max 50 words for complexity analysis. \\nIf the quiz is not up to the cognitive and analytical abilities of the students, update the quiz questions that need to be changed and adjust the tone to fit the student abilities. Only use at'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhana\\hugai\\env\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, comment êtes-vous?\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"t5-small\"  # Using a smaller model for testing\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Simple input for testing\n",
    "input_text = \"translate English to French: Hello, how are you?\" \n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate output\n",
    "outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the output to get the translation\n",
    "translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(translated_text)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhana\\hugai\\env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which of the following is the best choice for the first question?\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are an expert at creating multiple-choice questions (MCQs). Your task is to generate 5 MCQs based on the subject of machine learning. \n",
    "Make sure the questions are specific to machine learning concepts, such as supervised learning, algorithms, neural networks, and model evaluation. \n",
    "\n",
    "### Guidelines:\n",
    "- Each question should have 4 answer options labeled as \"a\", \"b\", \"c\", and \"d\".\n",
    "- Do not repeat questions.\n",
    "- Focus on generating questions that cover a range of difficulty levels.\n",
    "- Only generate the questions and options, do **not** provide the answers.\n",
    "\n",
    "### Response Format:\n",
    "{\n",
    "    \"1\": {\n",
    "        \"mcq\": \"First multiple-choice question related to machine learning.\",\n",
    "        \"options\": {\n",
    "            \"a\": \"First choice\",\n",
    "            \"b\": \"Second choice\",\n",
    "            \"c\": \"Third choice\",\n",
    "            \"d\": \"Fourth choice\"\n",
    "        }\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"Second multiple-choice question related to machine learning.\",\n",
    "        \"options\": {\n",
    "            \"a\": \"First choice\",\n",
    "            \"b\": \"Second choice\",\n",
    "            \"c\": \"Third choice\",\n",
    "            \"d\": \"Fourth choice\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Tokenize input prompt\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate the MCQs\n",
    "output = model.generate(**inputs, max_length=512, num_return_sequences=1)\n",
    "\n",
    "# Decode the output\n",
    "mcqs = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(mcqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which of the following is the best choice for the first question?\n"
     ]
    }
   ],
   "source": [
    "# Decode the output with clean_up_tokenization_spaces set to False\n",
    "mcqs = tokenizer.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "print(mcqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
